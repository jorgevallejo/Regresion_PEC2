---
title: "Regresión, modelos y métodos"
subtitle: "Prueba de evaluación continua 2"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document:
     toc: true
# pdf_document:
#   number_sections: true
# toc: true
# extra_dependencies: ["float"]
# urlcolor: blue
# header-includes:
#   - \renewcommand{\contentsname}{Índice}
# - \usepackage{float}

# Next code for knitting both types of documents automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
                    output_format = NULL,
                    output_dir = "results") })
# And:
# https://stackoverflow.com/a/46007686/10647267

# bibliography: references.bib
---
  
```{r setup, include=FALSE}
# knitr options

# Do not display code in output document
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center")
```

```{r estructura de directorios, results='hide', include=FALSE}
# 'data' contains raw source data.
# 'intermediateData' contains .RData objects with processed data.
# 'results' stores the final report files.

directories <- c("data", "results", "intermediateData", "images")

# Create directories
lapply(directories, function(x){
  if (!(dir.exists(x))){
    dir.create(x)
  }
})
```

```{r delete results files, eval= FALSE, include=FALSE}
# Run this chunk ONLY if you want to re-do
# the complete the report FROM THE ORIGINAL DATA.
# Remember that the .RData files are there to
# avoid unnecesarily redoing of long data processing.

directories <- c("results/", "intermediateData/", "images/")

file.remove(
  # Create a character vector of relative paths
  # to all files in the variable directories
  list.files(path = directories,
             all.files = TRUE,
             full.names = TRUE,
             recursive = TRUE)
)
```

```{r libraries, include=FALSE}
# Load packages
library(knitr)
# library(tseries)
library(faraway)
# library(car)
# library(MASS)
# library(dae)
library(corrplot) # Correlation plots
library(pls) # Principal component regression
```

# Ejercicio 1. Base de datos `diabetes.csv`

Como preparación al ejercicio, cargaremos los datos a memoria y examinaremos las características y estructura de los mismos.

```{r read data}
# Reading and loading data from file diabetes.txt
diabetes <- read.table("./data/diabetes.txt",
           header = TRUE
           )

kable(
  head(diabetes),
  caption = "Ejemplo de las primeras seis observaciones en la base de datos `diabetes`.",
  align = 'c'
)
```

Si examinamos la estructura de la base de datos:
```{r}
str(diabetes)
```

Vemos que se compone de de 377 observaciones y 11 variables. Todas las variables han sido correctamente identificadas como numéricas.

Finalmente, una forma rápida de buscar valores anómalos y valores ausentes es mediante el resumen numérico:
```{r}
summary(diabetes)
```

No parece haber valores anómalos (entendidos como exageradamente elevados o exageradamente pequeños) en ninguna de las variables. Por lo menos, en las variables _age_, _cintura_, _cadera_, _altura_ y _peso_; que tienen máximos y mínimos claramente dentro del rango esperable. En el resto de variables es más difícil de asegurar, ya que no estoy familiarizado con ellas e incluso algunas desconozco a qué se refieren. En cualquier caso, no parece haber ningún valor que destaque. Tampoco se ha detectado que falte ningún valor.

Finalmente, podríamos incluir un resumen gráfico de las variables para hacernos una idea de la distribución de valores en cada una:
```{r resumen_grafico, fig.cap="Gráficos de densidad mostrando la distribución de valores para cada una de las variables. Algunas de las variables, como _glyhb_, _stab.glu_ y _bp.1s_ parecen estar fuertemente sesgadas hacia valores bajos."}
par(mfrow=c(3,4))
for (i in 1:ncol(diabetes)){
plot(density(diabetes[,i]),
     main = colnames(diabetes[i]),
     xlab = "", ylab = "", yaxt = 'n')
}
```


## Ejercicio 1a. Ajustar un modelo lineal para explicar la variable hemoglobina glicosilada en función del resto de variables de la base de datos. Como el número de variables predictoras es elevado, investigar la posible multicolinealidad de este modelo de regresión.

Como primer paso, vamos a ajustar un modelo lineal con todas las variables predictoras

```{r hemo_mod1}
hemo_mod <- lm(glyhb ~ ., data = diabetes)
summary(hemo_mod)
```

Llama la atención lo pequeños que son los valores de los coeficientes de los predictores. Esto puede deberse a que los valores que adoptan las variables predictoras son uno o dos órdenes de magnitud superiores a los valores que adopta la variable respuesta. Para trabajar con unos coeficientes que sean menos confusos a la vista, cambiaremos la escala de la respuesta multiplicándola por 10 y ajustando los datos a un nuevo modelo:
```{r hemo_mod2}
hemo_mod <- lm(I(glyhb*10) ~ ., data = diabetes)
summary(hemo_mod)
```

Comprobamos que, efectivamente, los coeficientes (y los errores estándar) de los predictores son diez veces mayores que en el modelo anterior, lo que los hace más cómodos a ojos humanos. Sin embargo el resto de valores (estadísticos, p-valores, R^2) permanecen inalterados.

Si seguimos examinando el sumario de los tests estadísticos a partir del modelo, vemos que el valor de R^2 ajustado no es pequeño, lo que apunta a que el modelo recoge gran parte de la variación en los datos. Sin embargo, tan sólo dos de las variables predictoras es significativa. Eso podría significar que no afectan a la variable respuesta o podría ser un síntoma de **colinealidad**. La colinealidad (o multicolinealidad) es la situación en la que una variable predictora es una combinación lineal de otras. Dicho de otra forma, tenemos varios predictores que están midiendo lo mismo y, por tanto, no son ortogonales entre ellos.

Una forma rápida de comprobar qué variables se correlacionan entre ellas es representarlas por pares en gráficas de nubes de puntos:
```{r hemo_pairs}
pairs(diabetes[, -1])
```

A primera vista, las correlaciones más obvias son _cintura-cadera_, _cintura-peso_ y _cadera-peso_. Nada sorprendente si tenemos en cuenta dónde se acumula la mayor proporción de grasa corporal. Otra correlación que parece clara es _bp.1s-bp.1d_. Correlaciones más difusas podrían ser _altura-peso_, _chol-stab.glu_ y _chol-hdl_.

También podemos usar algo más preciso, como una **matriz de correlaciones**. Debido a la cantidad de variables, nos resultará más sencillo si la representamos en un gráfico de tipo mapa de calor:
```{r hemo_corr, fig.cap='Matriz de correlaciones. El color azul indica correlación positiva, el color rojo correlación negativa. El tamaño de los círculos y la saturación del color son proporcionales al grado de correlación.'}
corrplot(
round(cor(diabetes[, -1]),2),
type = 'upper',
diag = FALSE,
addCoef.col = "white",
tl.srt = 45
)
```

En este gráfico vemos fácilmente que casi todos los pares de variables muestran algún tipo de correlación. Destacan, como veíamos antes, los pares de medidas físicas directamente relacionados con la acumulación de grasa ( _cintura-peso_, _cintura-cadera_ y _cadera-peso_), y en menor medida los pares _bp.1d-bp.1s_ y _age-bp.1s_. Si pensamos que variables muy correlacionadas están básicamente midiendo lo mismo, podemos simplificar el modelo eligiendo una única variable de cada grupo de variables relacionadas. Por ejemplo, para el grupo _cintura_ - _peso_ - _cadera_ podemos elegir peso (la más fácil de medir); y del par _bp.1d-bp.1s_ quedarnos sólo con _bp.1d_.

Si ajustamos los datos al nuevo modelo:
```{r}
# Modelo sin cintura, cadera, ni bp.1s
# Multiplicamos glyhb por 10 para obtener coeficientes más legibles
hemo_mod_simp <- lm(I(glyhb*10) ~ chol + stab.glu + hdl + age + bp.1d + altura + peso, data = diabetes)
summary(hemo_mod_simp)
```

El modelo simplificado tiene un ajuste casi idéntico al del modelo completo según el valor de R^2 ajustado. La significatividad de los predictores dentro del modelo no parece haber cambiado, excepto por _age_, aunque ya tenía un p-valor un poco por encima de 0.05 en el modelo completo. El único aspecto en el que se aprecian grandes cambios es en los valores de los coeficientes de los predictores que no eran significativos en el modelo completo.


## 1b. Sabemos que en lugar de altura y peso, el IMC es un mejor indicador de obesidad y por otro lado, la ratio cintura/cadera es también mejor predictor que cintura y cadera por separado. Calcular estas variables y ajustar un modelo incluyéndolas en lugar de las originales y comparar ambos modelos. ¿Es posible un contraste para decidir entre ambos modelos?

En primer lugar, calcularemos el IMC (masa/estatura^2) y la ratio cintura-cadera y las añadiremos al resto de datos:
```{r}
## IMC
# We divide altura by 100 to change its units to meters
# because it is usually encoded that way for IMC
diabetes$imc <- diabetes$peso/(diabetes$altura/100)^2

## Ratio cintura/cadera
diabetes$ratiocc <- diabetes$cintura/diabetes$cadera
```

Y en segundo lugar, ajustamos los datos al modelo que tiene en cuenta el IMC y la ratio cintura/cadera:
```{r}
hemo_mod_imc <- lm(I(glyhb*10) ~ chol + stab.glu + hdl + age + bp.1s + bp.1d + ratiocc + imc, data = diabetes)
summary(hemo_mod_imc)
```

¿Cómo decidir entre ambos modelos? En primer lugar, comprobaremos si son equivalentes. A primera vista, el valor de R^2 ajustado es muy parecido:
```{r}
c('modelo original' = summary(hemo_mod)$adj.r.squared, 'modelo modificado' = summary(hemo_mod_imc)$adj.r.squared)
```

Seguidamente contrastaremos ambos modelos mediante un test _F_. A primera vista podríamos pensar que los modelos no están anidados porque las variables _IMC_ y _ratio_ no están en el modelo completo, y que tal contraste no es posible. Sin embargo, las variables _IMC_ y _ratio_ son combinaciones lineales de variables que sí están en el modelo completo, por tanto el contraste mediante un test _F_ tiene sentido.

Si los comparamos mediante ANOVA:
```{r}
anova(hemo_mod_imc, hemo_mod)
```

Vemos que, estadísticamente, ambos modelos son equivalentes (p-valor > 0.05). No parece haber razón para elegir uno sobre el otro.


## 1c. A partir del modelo mejorado del apartado anterior, ajustar un modelo de regresión con componentes principales y determinar el número de componentes óptimo que minimice el error cuadrático medio de predicción (o su raíz cuadrada).

Volvemos primeramente a examinar los valores de las variables para determinar si es necesario realizar algún tipo de escalado:

```{r}
# database with imc and ratiocc minus the variables
# included in these last variables
diabetes_modif <- diabetes[, ! names(diabetes) %in% c("cintura", "cadera", "altura", "peso")]
head(diabetes_modif)
```

Contemplamos diferencias de hasta tres órdenes de magnitud entre algunas variables (e.g. entre _chol_ y _ratiocc_). Esta diferencia haría que las variables con valores mayores estuvieran sobrerrepresentadas en las componentes principales al tener mayor varianza. Para evitar ese sesgo convertiremos los valores de todas las variables a unidades estándar (restando su media y dividiendo por su desviación estándar); y calcularemos las componentes principales a partir de esos valores:

```{r}
PC_diabetes_modif <- prcomp(diabetes_modif[, 2:9], scale = TRUE)
summary(PC_diabetes_modif)
```

Vemos que en este caso la varianza está muy repartido. Necesitamos hasta 5 componentes principales para reunir al menos el 80% de la varianza, y 7 para reunir más del 90% de la misma.

Por curiosidad, veamos cuál es la aportación de las variables a cada componente principal:
```{r}
round(PC_diabetes_modif$rotation, digits = 2)
```

Para decidir cuántas componentes principales incluir como predictores en el modelo, buscaremos la combinación de predictores que ofrece predicciones con menor RMSE (raíz del error cuadrático medio). El método que usaremos para dividir las observaciones del set de datos en entrenamiento y validación de los modelos será el de validación cruzada (usando 10 segmentos aleatorios de los datos). Utilizaremos funciones del paquete `pls` del lenguaje **R**:

```{r, fig.cap="Representación de la raíz del error cuadrático medio según el número de componentes usado en la predicción de la variable glyhb. El objetivo es obtener averiguar cuántos componentes ofrecen el menor error medio."}
# Regresion sobre componentes principales
set.seed(12021021)
PC_reg <- pcr(glyhb ~ ., data = diabetes_modif, 
              scale = TRUE, 
              validation = "CV", 
              ncomp = 8)
# Estimate the RMSEP by cross-validation
PC_reg_CV <- RMSEP(PC_reg, estimate = "CV")
# Components at which RMSEP in minimum
min_comp <- which.min(PC_reg_CV$val)
# Plot
plot(PC_reg_CV,
     main = "RMSEP de la predicción por número de componentes",
     xlab = "Número de componentes")
text(min_comp-1, # x coord is components
     y = round(PC_reg_CV$val[min_comp], digits = 2)*1.05, # y coord is RMSEP plus 10%
     labels = round(PC_reg_CV$val[min_comp],2)) # text is RMSEP value
```

Vemos con bastante claridad en el gráfico que `r min_comp-1`  es la cantidad de componentes con la que obtenemos mejores predicciones de los valores de la variable respuesta _glyhb_ en nuestro set de datos.

Finalmente, una vez decididas la cantidad de componentes principales óptima según nuestro set de datos, procedemos a reajustar el modelo de regresión:

```{r}
set.seed(5500)
PC_reg_mod <- pcr(glyhb ~ ., data = diabetes_modif, 
              scale = TRUE, 
              validation = "CV", 
              ncomp = 7)
```





# Apéndice A: Código

El documento original en formato .Rmd, que incluye el código completo en lenguaje R usado para generar este informe, se puede consultar y descargar en el siguiente repositorio de Github:
[jorgevallejo/regresion_PEC1](https://github.com/jorgevallejo/regresion_PEC1)

# Apéndice B: Reproducibilidad {#apendiceB}
```{r session_info, include=TRUE, echo=TRUE, results='markup'}
sessionInfo() # For better reproducibility
```


# Referencias